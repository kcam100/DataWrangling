{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "# OpenStreetMap Data Wrangling with Python and SQL \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**By:** Kyle Campbell <br>  **Date:** September 22, 2017 \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Area\n",
    "Las Vegas, Nevada, United States\n",
    "+ https://mapzen.com/data/metro-extracts/metro/las-vegas_nevada/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recently went to Las Vegas for my brother's bachelor party. After an eventful weekend, I thought about how we got to check out so many casinos, restaurants, and other amenities, yet it was impossible to see even a fraction of everything the city has to offer. In effect, this sparked my curiosity to choose Las Vegas as the city to audit and clean. I have four main objectives for this project:\n",
    "+ Audit the Las Vegas OSM file to assess the quality of user-input data\n",
    "+ Clean up street names and other problematic data in the Las Vegas file by writing Python cleaning functions\n",
    "+ Process this cleaned data by exporting it into structured CSV files\n",
    "+ Import these CSV files into an SQL database and query the db for additional information\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "# Initial Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Tag Count\n",
    "After shrinking the original OSM file down to a 5% sample by exporting every 20th top level element, I first viewed the data in raw XML format to get a firsthand look at the structure of the data. For the next step in this audit I would like to get an overview of our OSM file by confirming what tags are being utilized, as well as the count for each tag. I do this by running the code in ```VegasMapParse.py``` which parses the Vegas OSM file and returns a dictionary with the following counts:\n",
    "\n",
    "+ **bounds**: 1\n",
    "+ **member**: 4403\n",
    "+ **nd**: 1248586\n",
    "+ **node**: 1052896\n",
    "+ **osm**: 1\n",
    "+ **relation**: 555\n",
    "+ **tag**: 491531\n",
    "+ **way**: 112680"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Las Vegas OSM Tag Types\n",
    "Next, I want to identify problematic 'k' tag values. I can do this by placing the 'k' tags into four different categories: \n",
    "+ **lower**: tags that contain only lowercase letters and are valid\n",
    "+ **lower_colon**: tags that are valid except for a colon somewhere within\n",
    "+ **problemchars**: tags that contain problematic characters\n",
    "+ **other**: tags that do not fall into any of the three above categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code from ```VegasTagTypes.py``` returns a count of each of these 'k' tag types:\n",
    "+ **lower**: 318466\n",
    "+ **lower_colon**: 165728\n",
    "+ **problemchars**: 0\n",
    "+ **other**: 7337\n",
    "\n",
    "> *I was surprised to see that the Las Vegas OSM file contained zero problem character 'k' tags, yet had over 7337 'other' tag types. After printing out the results of the 'other' 'k' tag attributes, I can see that most of these results fell into this category due to a colon coinciding with capital letters and/or underscores.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique User Contributions\n",
    "Before auditing the Las Vegas OSM data, the last thing I would like to take a look at is the unique user count of people who have contributed to this map. After running the code from ```VegasUserCount.py``` I found that **1,102 unique user IDs** have contributed to the Vegas OSM file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>\n",
    "# Problems Encountered in the Map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three main issues with the Las Vegas OSM data that I wanted to audit and address were:\n",
    "+ Street names needing corrected (i.e. st. -> Street)\n",
    "+ City name inconsistencies (las vegas -> Las Vegas)\n",
    "+ State name inconsistencies (nV -> NV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following will be an overview of the three items I audited as well as code from the  ```VegasAudit.py``` file.\n",
    "\n",
    "**************************************************************************\n",
    "## Street Name Audit\n",
    "\n",
    "For the **street name** audit, most of the problems encountered were with abbreviations or street names being all lowercase, and were updated such as:\n",
    "+ Rd -------> Road\n",
    "+ Ste ------> Suite\n",
    "+ Ave. -----> Avenue\n",
    "+ N. -------> North\n",
    "+ drive ----> Drive\n",
    "\n",
    "\n",
    "## Street Name Code\n",
    "\n",
    "```python\n",
    "# Audit street types and return list\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City Name Audit\n",
    "While auditing the **city name**, I found a number of variations of 'Las Vegas', such as 'las vegas', 'Las Vegas, NV', and 'LAS VEGAS'. Instead of replacing them all with 'Las Vegas', I specified individual ```if``` statements because a few of the results from the audit returned city results of 'Henderson', 'Spring Valley', and 'Indian Springs'.\n",
    "\n",
    "## City Name Code\n",
    "```python\n",
    "# Audit city name\n",
    "def city_name_audit(osmfile):\n",
    "    osm_file = open(osmfile, 'r')\n",
    "    not_city = set()\n",
    "    for event, element in ET.iterparse(osm_file, events=('start',)):\n",
    "        \n",
    "        if element.tag == 'node' or element.tag == 'way':\n",
    "            for tag in element.iter('tag'):\n",
    "                if is_city(tag):\n",
    "                    if tag.attrib['v'] != 'Las Vegas':\n",
    "                        not_city.add(tag.attrib['v'])\n",
    "                        \n",
    "    osm_file.close()\n",
    "    return not_city\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Name Audit\n",
    "While auditing the **state name**, my results were a set that included ```(['CA', 'AZ', 'nv', 'Nevada'])```. I decided to leave the 'CA' and 'AZ' tags alone, but I updated the 'nv' and 'Nevada' tags to reflect the proper 'NV' state name.\n",
    "\n",
    "## State Name Code\n",
    "```python\n",
    "# Audit state name\n",
    "def state_name_audit(osmfile):\n",
    "    osm_file = open(osmfile, 'r')\n",
    "    not_expected = set()\n",
    "    for event, element in ET.iterparse(osm_file, events=('start',)):\n",
    "        \n",
    "        if element.tag == 'node' or element.tag == 'way':\n",
    "            for tag in element.iter('tag'):\n",
    "                if is_state(tag):\n",
    "                    if tag.attrib['v'] != 'NV':\n",
    "                        not_expected.add(tag.attrib['v'])\n",
    "                        \n",
    "    osm_file.close()\n",
    "    return not_expected\n",
    "```\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "# Preparing Data for Database Insertion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing the audit of the Las Vegas OSM data, the next step is to write the cleaning functions and prepare the data to be exported to .CSV tabular format which can then be imported into a SQL database. The full code for shaping the data and exporting it into .CSVs, including the ```shape_element()``` function, can be found in the ```VegasData.py``` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>\n",
    "# Overview of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data has been exported to .CSV files, I can use Python to build an SQL database to run additional queries on the data. All of the following code can be referenced in ```SQLquery.py```. Let's take a look at the file sizes for the original Las Vegas OSM data, as well as the sample and CSVs we created earlier:\n",
    "+ **las-vegas_nevada.osm**: ```216 MB```\n",
    "+ **sample.osm**: ```11 MB```\n",
    "+ **nodes.csv**: ```4.23 MB```\n",
    "+ **nodes_tags.csv**: ```119 KB ```\n",
    "+ **ways.csv**: ```332 KB```\n",
    "+ **ways_tags.csv**: ```738 KB```\n",
    "+ **ways_nodes.csv**: ```1.55 MB```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Number of Unique Users:\n",
    "```python\n",
    "def unique():\n",
    "    u = c.execute('''SELECT COUNT(DISTINCT(uid))          \n",
    "                      FROM (SELECT uid FROM nodes UNION\n",
    "                            SELECT uid FROM ways)''')\n",
    "    return u.fetchone()[0]\n",
    "print unique()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: 590"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Number of Nodes:\n",
    "```python\n",
    "def node_count():\n",
    "    nc = c.execute('''SELECT COUNT(*) FROM nodes''')\n",
    "    return nc.fetchone()[0]\n",
    "print node_count()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: 52645"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Number of Ways:\n",
    "```python\n",
    "def ways_count():\n",
    "    w = c.execute('''SELECT COUNT(*) FROM ways''')\n",
    "    return w.fetchone()[0]\n",
    "print ways_count()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: 5634"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Number of Cafes:\n",
    "```python\n",
    "def cafe_count():\n",
    "    cc = c.execute('''SELECT COUNT(*) FROM nodes_tags\n",
    "                      WHERE nodes_tags.value = 'cafe' OR\n",
    "                      nodes_tags.value = 'coffee_shop' ''')\n",
    "    return cc.fetchone()[0]\n",
    "print cafe_count()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>\n",
    "# Additional Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Contributing Users:\n",
    "```python\n",
    "def top_contributing():\n",
    "    uc = []\n",
    "    for row in c.execute('''SELECT user, COUNT(user) as NUM\n",
    "                            FROM (SELECT user FROM nodes UNION ALL \n",
    "                                  SELECT user FROM ways) \n",
    "                            GROUP BY user \n",
    "                            ORDER BY NUM DESC \n",
    "                            LIMIT 10'''):\n",
    "                                uc.append(row)\n",
    "    return uc\n",
    "print top_contributing()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: \n",
    "+ (u'alimamo', 12593)\n",
    "+ (u'tomthepom', 6058)\n",
    "+ (u'woodpeck_fixbot', 3527) \n",
    "+ (u'alecdhuse', 3319)\n",
    "+ (u'abellao', 2780)\n",
    "+ (u'gMitchellD', 2241)\n",
    "+ (u'robgeb', 2052)\n",
    "+ (u'nmixter', 2000)\n",
    "+ (u'TheDutchMan13', 1960)\n",
    "+ (u'Tom_Holland', 1655)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Most Popular Religion:\n",
    "```python\n",
    "def religion():\n",
    "    mpr = c.execute('''SELECT nodes_tags.value, COUNT(*) as NUM\n",
    "                       FROM nodes_tags JOIN \n",
    "                       (SELECT DISTINCT(id) FROM nodes_tags \n",
    "                       WHERE value='place_of_worship') pow\n",
    "                       ON nodes_tags.id = pow.id\n",
    "                       WHERE nodes_tags.key='religion'\n",
    "                       GROUP BY nodes_tags.value\n",
    "                       ORDER BY num DESC \n",
    "                       LIMIT 1''')\n",
    "    return mpr.fetchone()[0]\n",
    "print religion()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: christian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Number of Schools:\n",
    "**(Including kindergarden - college total count)**\n",
    "```python\n",
    "def schools():\n",
    "    s = c.execute('''SELECT COUNT(*) as NUM\n",
    "                     FROM nodes_tags\n",
    "                     WHERE nodes_tags.value = 'school' OR\n",
    "                     nodes_tags.value = 'college' OR\n",
    "                     nodes_tags.value = 'kindergarden' OR\n",
    "                     nodes_tags.value = 'university' ''')\n",
    "    return s.fetchone()[0]\n",
    "print schools()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Number of Casinos:\n",
    "```python\n",
    "def casinos():\n",
    "    cas = c.execute(''' SELECT COUNT(*) as NUM\n",
    "                        FROM ways_tags\n",
    "                        WHERE ways_tags.value = 'casino' OR\n",
    "                        ways_tags.value = 'adult_gaming_centre' OR\n",
    "                        ways_tags.value = 'amusement_arcade' OR\n",
    "                        ways_tags.value = 'gambling' ''')\n",
    "    return cas.fetchone()[0]\n",
    "print casinos()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output**: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>\n",
    "# Conclusion & Additional Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting a thorough look at the Las Vegas OSM data, I feel that the data was fairly clean for the most part. The errors that I encountered with street name, city, and state values were most likely due to user input error. If I had to make an assumption about the overall OpenStreetMap data quality, it would make sense that the urban areas would have the most contributions, while there are most likely a number of rural areas that need a thorough audit/cleaning.\n",
    "<br><br>\n",
    "One way that the OpenStreetMap data could become more accurate would be to **gamify map contributions**. There are a few ways this could be executed. One way could be to have leaderboards which would feature the top contributors to the OpenStreetMap project, excluding bots. Another way to validate the accuracy of map data would be to create a script that executes randomly for people looking at a certain section of the map. For example, if I was searching for cafes in New York City, a pop up in the map could confirm the validity of results. Updated names could be input by the user, and then once enough consensus was built around the updated name, it would execute script to update the value. \n",
    "<br><br>\n",
    "A potential downfall to my suggested strategy would be that user input is fallible. If it wasn't, we would have no reason to clean the data. This could potentially lead to even more messy user-input data, so it would be best to test it on a sample in target areas. On the other hand, the upside of having users themselves contribute to map values is that a more precise, up to date, opensource map could exist. The best strategy would be to execute updates on a sample area, and then after a certain amount of time has elapsed compare the old data to the updated data to see if the implementation was successful. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
